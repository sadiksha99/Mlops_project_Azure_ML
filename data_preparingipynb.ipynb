{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### setting up the environment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749236860990
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "## Either get environment variables, or a fallback name, which is the second parameter.\n",
        "## Currently, fill in the fallback values. Later on, we will make sure to work with Environment values. So we're already preparing for it in here!\n",
        "workspace_name = os.environ.get('WORKSPACE', 'ml-workspace')\n",
        "subscription_id = os.environ.get('SUBSCRIPTION_ID', '72b19ebb-8177-4d32-a321-da2a8bd06ccb')\n",
        "resource_group = os.environ.get('RESOURCE_GROUP', 'mlops-project')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749236862578
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The credential \"DefaultAzureCredential\" will use the same name as your logged in user.\n",
        "credential = DefaultAzureCredential()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749236863597
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client = MLClient(\n",
        "    credential, subscription_id, resource_group, workspace_name\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749236870616
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Folder and file path\n",
        "folder_path = \"./components/dataprep\"\n",
        "file_path = os.path.join(folder_path, \"conda.yaml\")\n",
        "\n",
        "# Create folder structure if it doesn't exist\n",
        "os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "# YAML content\n",
        "conda_yaml_content = \"\"\"\n",
        "name: aml-Pillow\n",
        "channels:\n",
        "  - conda-forge\n",
        "dependencies:\n",
        "  - python=3.8\n",
        "  - numpy=1.21.2\n",
        "  - pip=21.2.4\n",
        "  - scikit-learn=0.24.2\n",
        "  - scipy=1.7.1\n",
        "  - pandas>=1.1,<1.2\n",
        "  - pip:\n",
        "    - inference-schema[numpy-support]==1.3.0\n",
        "    - xlrd==2.0.1\n",
        "    - mlflow==1.26.1\n",
        "    - azureml-mlflow==1.42.0\n",
        "    - Pillow==10.0.1\n",
        "\"\"\"\n",
        "\n",
        "# Write to file\n",
        "with open(file_path, \"w\") as f:\n",
        "    f.write(conda_yaml_content)\n",
        "\n",
        "print(\" conda.yaml written to\", file_path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749198147274
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pillow lets you work with images inside your Azure ML (AML) projects."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "import os\n",
        "\n",
        "custom_env_name = \"aml-Pillow\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for Image Processing (with Pillow)\",\n",
        "    tags={\"Pillow\": \"10.0.1\"},\n",
        "    conda_file=os.path.join(\"components\", \"dataprep\", \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749203018976
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating components"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparing "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command\n",
        "from azure.ai.ml import Input, Output\n",
        "import os\n",
        "\n",
        "# Define the data prep component\n",
        "data_prep_component = command(\n",
        "    name=\"data_prep_png_to_jpg\",\n",
        "    display_name=\"Data Preparation - PNG to JPG (28x28)\",\n",
        "    description=\"Converts 28x28 PNG images to JPG format.\",\n",
        "    inputs={\n",
        "        \"data\": Input(type=\"uri_folder\"),\n",
        "    },\n",
        "    outputs={\n",
        "        \"output_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    },\n",
        "    code=os.path.join(\"components\", \"dataprep\", \"code\"),  # Must contain dataprep.py\n",
        "    command=\"\"\"\n",
        "        python dataprep.py \\\n",
        "        --data ${{inputs.data}} \\\n",
        "        --output_data ${{outputs.output_data}}\n",
        "    \"\"\",\n",
        "    environment=\"aml-Pillow@latest\",\n",
        ")\n",
        "\n",
        "# Register the component\n",
        "data_prep_component = ml_client.create_or_update(data_prep_component.component)\n",
        "\n",
        "print(\n",
        "    f\"âœ… Component {data_prep_component.name} (v{data_prep_component.version}) registered\"\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749203026099
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"compute-sadikshasapkota\",\n",
        "    description=\"Data preprocessing for MNIST folders\"\n",
        ")\n",
        "def mnist_preprocessing_pipeline():  # ðŸš« no input_version here\n",
        "    jobs = {}\n",
        "\n",
        "    input_version = \"1\"  # âœ… hardcoded â€” this is the fix\n",
        "    workspace_name = os.environ.get('WORKSPACE', 'ml-workspace')\n",
        "    subscription_id = os.environ.get('SUBSCRIPTION_ID', '72b19ebb-8177-4d32-a321-da2a8bd06ccb')\n",
        "    resource_group = os.environ.get('RESOURCE_GROUP', 'mlops-project')\n",
        "\n",
        "    for i in range(10):\n",
        "        label = str(i)\n",
        "        folder_name = f\"minst-{i}\"\n",
        "\n",
        "        data_prep_job = data_prep_component(\n",
        "            data=Input(\n",
        "                type=\"uri_folder\",\n",
        "                path=f\"azureml:{folder_name}:{input_version}\"  # âœ… this will resolve correctly now\n",
        "            )\n",
        "        )\n",
        "\n",
        "        output_path = (\n",
        "            f\"azureml://subscriptions/{subscription_id}/resourcegroups/{resource_group}/\"\n",
        "            f\"workspaces/{workspace_name}/datastores/workspaceblobstore/paths/processed_mnist/{label}\"\n",
        "        )\n",
        "\n",
        "        data_prep_job.outputs.output_data = Output(\n",
        "            type=\"uri_folder\",\n",
        "            path=output_path,\n",
        "            name=f\"mnist_{label}_jpg\",\n",
        "            mode=\"rw_mount\"\n",
        "        )\n",
        "\n",
        "        jobs[f\"label_{label}\"] = data_prep_job\n",
        "\n",
        "    return {\n",
        "        f\"label_{label}\": job.outputs.output_data for label, job in jobs.items()\n",
        "    }\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749203028222
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = mnist_preprocessing_pipeline()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749203035543
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import webbrowser\n",
        "# Submit the pipeline job\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline,\n",
        "    experiment_name=\"mnist_preprocessing_pipeline\"\n",
        ")\n",
        "\n",
        "# Open the job in Azure ML Studio\n",
        "webbrowser.open(pipeline_job.studio_url)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749203040001
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train test split"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command, Input, Output\n",
        "from azure.ai.ml.entities import Environment\n",
        "\n",
        "data_split_component = command(\n",
        "    name=\"mnist_data_split\",\n",
        "    display_name=\"Split MNIST Datasets\",\n",
        "    description=\"Splits 10 MNIST datasets into training and testing sets.\",\n",
        "    inputs={\n",
        "        \"mnist_0\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_1\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_2\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_3\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_4\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_5\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_6\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_7\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_8\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_9\": Input(type=\"uri_folder\"),\n",
        "        \"train_test_split_factor\": Input(type=\"number\"),\n",
        "    },\n",
        "    outputs={\n",
        "        \"training_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "        \"testing_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    },\n",
        "    code=\"Components/dataprep/code\",  # must contain traintestsplit.py\n",
        "    command=\"\"\"python traintestsplit.py \\\n",
        "        --datasets ${{inputs.mnist_0}} ${{inputs.mnist_1}} ${{inputs.mnist_2}} \\\n",
        "                  ${{inputs.mnist_3}} ${{inputs.mnist_4}} ${{inputs.mnist_5}} \\\n",
        "                  ${{inputs.mnist_6}} ${{inputs.mnist_7}} ${{inputs.mnist_8}} \\\n",
        "                  ${{inputs.mnist_9}} \\\n",
        "        --split_size ${{inputs.train_test_split_factor}} \\\n",
        "        --training_data_output ${{outputs.training_data}} \\\n",
        "        --testing_data_output ${{outputs.testing_data}} \\\n",
        "    \"\"\",\n",
        "    environment=\"aml-Pillow@latest\",\n",
        ")\n",
        "\n",
        "data_split_component = ml_client.create_or_update(data_split_component.component)\n",
        "print(f\"âœ… Component registered: {data_split_component.name}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749218675245
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"compute-sadikshasapkota\",\n",
        "    description=\"Custom data_split pipeline for MNIST 0-9\"\n",
        ")\n",
        "def mnist_images_traintest_split_pipeline(\n",
        "    train_test_split: int,\n",
        "    mnist_0: Input,\n",
        "    mnist_1: Input,\n",
        "    mnist_2: Input,\n",
        "    mnist_3: Input,\n",
        "    mnist_4: Input,\n",
        "    mnist_5: Input,\n",
        "    mnist_6: Input,\n",
        "    mnist_7: Input,\n",
        "    mnist_8: Input,\n",
        "    mnist_9: Input,\n",
        "):\n",
        "    data_split_job = data_split_component(\n",
        "        mnist_0=mnist_0,\n",
        "        mnist_1=mnist_1,\n",
        "        mnist_2=mnist_2,\n",
        "        mnist_3=mnist_3,\n",
        "        mnist_4=mnist_4,\n",
        "        mnist_5=mnist_5,\n",
        "        mnist_6=mnist_6,\n",
        "        mnist_7=mnist_7,\n",
        "        mnist_8=mnist_8,\n",
        "        mnist_9=mnist_9,\n",
        "        train_test_split_factor=train_test_split\n",
        "    )\n",
        "\n",
        "    data_split_job.outputs.training_data = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"training_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "    data_split_job.outputs.testing_data = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"testing_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"training_data\": data_split_job.outputs.training_data,\n",
        "        \"testing_data\": data_split_job.outputs.testing_data\n",
        "    }\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749218711892
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version = \"1\"\n",
        "mnist_inputs = {\n",
        "    f\"mnist_{i}\": Input(type=\"uri_folder\", path=f\"azureml:mnist_{i}_jpg:{version}\")\n",
        "    for i in range(10)\n",
        "}\n",
        "\n",
        "train_test_pipeline = mnist_images_traintest_split_pipeline(\n",
        "    **mnist_inputs,\n",
        "    train_test_split=20\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749218713790
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import webbrowser\n",
        "\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    train_test_pipeline,\n",
        "    experiment_name=\"mnist_split_experiment\",\n",
        ")\n",
        "webbrowser.open(pipeline_job.studio_url)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749218717945
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainng the model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Environment and compnents pipeline registering"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "import os\n",
        "\n",
        "custom_env_name = \"aml-Tensorflow-Pillow\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for AI Training (with Pillow)\",\n",
        "    tags={\"Pillow\": \"10.0.1\", \"Tensorflow\": \"2.4.1\"},\n",
        "    conda_file=os.path.join(\"components\", \"training\", \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749225610303
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.ai.ml import command, Input, Output\n",
        "\n",
        "# Define the training component\n",
        "training_component = command(\n",
        "    name=\"mnist_training\",\n",
        "    display_name=\"Training MNIST CNN\",\n",
        "    description=\"Trains a CNN on MNIST JPG images\",\n",
        "    inputs={\n",
        "        \"training_folder\": Input(type=\"uri_folder\"),\n",
        "        \"testing_folder\": Input(type=\"uri_folder\"),\n",
        "        \"epochs\": Input(type=\"number\"),\n",
        "    },\n",
        "    outputs={\n",
        "        \"output_folder\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    },\n",
        "    code=os.path.join(\"components\", \"training\", \"code\"),  # must contain train.py and utils.py\n",
        "    command=\"\"\"python train.py \\\n",
        "        --training_folder ${{inputs.training_folder}} \\\n",
        "        --testing_folder ${{inputs.testing_folder}} \\\n",
        "        --output_folder ${{outputs.output_folder}} \\\n",
        "        --epochs ${{inputs.epochs}}\"\"\",\n",
        "    environment=\"aml-Tensorflow-Pillow@latest\",\n",
        ")\n",
        "\n",
        "# Register the component\n",
        "training_component = ml_client.create_or_update(training_component.component)\n",
        "print(f\"âœ… Registered: {training_component.name} (v{training_component.version})\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749226014596
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"compute-sadikshasapkota\",\n",
        "    description=\"MNIST Training Pipeline\",\n",
        ")\n",
        "def mnist_training_pipeline(\n",
        "    training_folder: Input,\n",
        "    testing_folder: Input,\n",
        "    epochs: int,\n",
        "):\n",
        "    training_job = training_component(\n",
        "        training_folder=training_folder,\n",
        "        testing_folder=testing_folder,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "    training_job.outputs.output_folder = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"output_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"output_data\": training_job.outputs.output_folder,\n",
        "    }\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749226014732
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_pipeline = mnist_training_pipeline(\n",
        "    training_folder=Input(type=\"uri_folder\", path=\"azureml:training_data:1\"),\n",
        "    testing_folder=Input(type=\"uri_folder\", path=\"azureml:testing_data:1\"),\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "import webbrowser\n",
        "\n",
        "training_pipeline_job = ml_client.jobs.create_or_update(\n",
        "    training_pipeline,\n",
        "    experiment_name=\"mnist_training_pipeline\"\n",
        ")\n",
        "\n",
        "# Open the job in your browser\n",
        "webbrowser.open(training_pipeline_job.studio_url)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749226016417
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chaining the whole pipeline together"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prep = ml_client.components.get(name=\"data_prep_png_to_jpg\", version=\"1\")\n",
        "split = ml_client.components.get(name=\"mnist_data_split\", version=\"1\")\n",
        "train = ml_client.components.get(name=\"mnist_training\", version=\"1\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749236992843
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline(default_compute=\"compute-sadikshasapkota\")\n",
        "def full_mnist_pipeline(\n",
        "    raw_input: Input,\n",
        "    split_ratio: float = 20.0,\n",
        "    epochs: int = 5\n",
        "):\n",
        "    # Fix: this component only accepts `data`, and it returns a default output (often just `.outputs.output`)\n",
        "    prep_step = prep(\n",
        "        data=raw_input\n",
        "    )\n",
        "\n",
        "    # This assumes `prep_step.outputs.output` is a single folder with all images\n",
        "    split_step = split(\n",
        "    datasets=[prep_step.outputs.output_data],  # âœ… expects list\n",
        "    split_size=split_ratio                     # âœ… correct key name\n",
        ")\n",
        "\n",
        "\n",
        "    train_step = train(\n",
        "        training_folder=split_step.outputs.training_data,\n",
        "        testing_folder=split_step.outputs.testing_data,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"trained_model\": train_step.outputs.output_folder\n",
        "    }\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749237237411
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_job = full_mnist_pipeline(\n",
        "    raw_input=Input(\n",
        "        type=\"uri_folder\",\n",
        "        path=\"azureml:mnist_raw_dataset:1\"\n",
        "    ),\n",
        "    split_ratio=20.0,\n",
        "    epochs=5\n",
        ")\n",
        "\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline_job,\n",
        "    experiment_name=\"mnist_full_pipeline\"\n",
        ")\n",
        "\n",
        "pipeline_job\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749237242280
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}