{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1749416873220
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "## Either get environment variables, or a fallback name, which is the second parameter.\n",
        "## Currently, fill in the fallback values. Later on, we will make sure to work with Environment values. So we're already preparing for it in here!\n",
        "workspace_name = os.environ.get('WORKSPACE', 'sadiksha-sapkota-ml')\n",
        "subscription_id = os.environ.get('SUBSCRIPTION_ID', 'c2427130-ac1b-4b29-a374-ae5927fe5c99')\n",
        "resource_group = os.environ.get('RESOURCE_GROUP', 'mlops-project')"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1749416873572
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The credential \"DefaultAzureCredential\" will use the same name as your logged in user.\n",
        "credential = DefaultAzureCredential()"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1749416873760
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ml_client = MLClient(\n",
        "    credential, subscription_id, resource_group, workspace_name\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1749416880018
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Instances need to have a unique name across the region.\n",
        "from azure.ai.ml.entities import ComputeInstance, AmlCompute\n",
        "\n",
        "ci_basic_name = \"cpu-sadiksha-auto\" # I add the suffix Auto, because we are automatically creating this instance.\n",
        "ci_basic = ComputeInstance(name=ci_basic_name, size=\"STANDARD_DS3_v2\")\n",
        "ml_client.begin_create_or_update(ci_basic).result()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "import os\n",
        "\n",
        "custom_env_name = \"aml-Pillow\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for Image Processing (with Pillow)\",\n",
        "    tags={\"Pillow\": \"10.0.1\"},\n",
        "    conda_file=os.path.join(\"components\", \"dataprep\", \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749399882256
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data cleaning component and pipeline"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command, Input, Output, MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from pathlib import Path\n",
        "\n",
        "# Use absolute path to the code directory\n",
        "code_path = Path(\"components/dataprep/code\").resolve()\n",
        "\n",
        "# Define and register the component\n",
        "convert_resize_component = command(\n",
        "    name=\"convert_resize_images\",\n",
        "    display_name=\"Convert PNG to JPG and Resize\",\n",
        "    description=\"Convert .png to .jpg and resize to 64x64.\",\n",
        "    inputs={\"data\": Input(type=\"uri_folder\")},\n",
        "    outputs={\"output_data\": Output(type=\"uri_folder\", mode=\"rw_mount\")},\n",
        "    code=str(code_path),  # ✅ this is the correct usage\n",
        "    command=\"python dataprep.py --data ${{inputs.data}} --output_data ${{outputs.output_data}}\",\n",
        "    environment=\"aml-Pillow@latest\",\n",
        ")\n",
        "\n",
        "# Register the component\n",
        "registered_component = ml_client.create_or_update(convert_resize_component.component)\n",
        "\n",
        "print(f\"✅ Registered: {registered_component.name} v{registered_component.version}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749400342614
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"cpu-sadiksha-auto\",\n",
        "    description=\"MNIST preprocessing pipeline: PNG → JPG\"\n",
        ")\n",
        "def mnist_preprocessing_pipeline(\n",
        "    input_version: str,\n",
        "    output_version: str,\n",
        "):\n",
        "    # Internal keys must use underscores\n",
        "    digits = [\n",
        "        (\"mnist_2\", \"mnist-2\", \"1\"),\n",
        "        (\"mnist_7\", \"mnist-7\", \"1\"),\n",
        "        (\"mnist_8\", \"mnist-8\", \"1\"),\n",
        "    ]\n",
        "\n",
        "    jobs = {}\n",
        "\n",
        "    for key, dataset_name, version in digits:\n",
        "        resize_job = convert_resize_component(\n",
        "            data=Input(\n",
        "                type=\"uri_folder\",\n",
        "                path=f\"azureml:{dataset_name}:{version}\"\n",
        "            )\n",
        "        )\n",
        "\n",
        "        output_path = (\n",
        "            \"azureml://subscriptions/c2427130-ac1b-4b29-a374-ae5927fe5c99\"\n",
        "            \"/resourcegroups/mlops-project\"\n",
        "            \"/workspaces/sadiksha-sapkota-ml\"\n",
        "            f\"/datastores/workspaceblobstore/paths/processed_mnist/{dataset_name}\"\n",
        "        )\n",
        "\n",
        "        resize_job.outputs.output_data = Output(\n",
        "            type=\"uri_folder\",\n",
        "            path=output_path,\n",
        "            name=f\"{key}_jpg\",\n",
        "            mode=\"rw_mount\"\n",
        "        )\n",
        "\n",
        "        jobs[key] = resize_job\n",
        "\n",
        "    return {k: v.outputs.output_data for k, v in jobs.items()}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749400612007
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's instantiate the pipeline with the parameters of our choice\n",
        "pipeline = mnist_preprocessing_pipeline()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749400618333
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import webbrowser\n",
        "\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    pipeline,\n",
        "    experiment_name=\"image_preprocessing_pipeline\"\n",
        ")\n",
        "webbrowser.open(pipeline_job.studio_url)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749400623738
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train-test split"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: component definition (e.g. components/dataprep/register_split_component.py)\n",
        "from azure.ai.ml import command, Input, Output\n",
        "import os\n",
        "\n",
        "mnist_data_split_component = command(\n",
        "    name=\"mnist_data_split\",\n",
        "    display_name=\"MNIST Data Splitting to Train and Test\",\n",
        "    description=\"Splits digit datasets into training and testing sets\",\n",
        "    inputs={\n",
        "        \"mnist_2_jpg\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_7_jpg\": Input(type=\"uri_folder\"),\n",
        "        \"mnist_8_jpg\": Input(type=\"uri_folder\"),\n",
        "        \"train_test_split_factor\": Input(type=\"number\")\n",
        "    },\n",
        "    outputs={\n",
        "        \"training_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "        \"testing_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    },\n",
        "    code=os.path.join(\"components\", \"dataprep\", \"code\"),\n",
        "    command=\"\"\"python traintestsplit.py \\\n",
        "        --datasets ${{inputs.mnist_2_jpg}} ${{inputs.mnist_7_jpg}} ${{inputs.mnist_8_jpg}} \\\n",
        "        --split_size ${{inputs.train_test_split_factor}} \\\n",
        "        --training_data_output ${{outputs.training_data}} \\\n",
        "        --testing_data_output ${{outputs.testing_data}}\"\"\",\n",
        "    environment=\"aml-Pillow@latest\",\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749409439473
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FILE: pipeline definition (e.g. pipelines/mnist_split_pipeline.py)\n",
        "from azure.ai.ml import dsl, Input, Output\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"cpu-sadiksha-auto\",\n",
        "    description=\"MNIST split pipeline using JPG inputs\"\n",
        ")\n",
        "def mnist_images_traintest_split_pipeline(\n",
        "    train_test_split: int,\n",
        "    mnist_2_jpg: Input,\n",
        "    mnist_7_jpg: Input,\n",
        "    mnist_8_jpg: Input,\n",
        "):\n",
        "    split_job = mnist_data_split_component(\n",
        "        mnist_2_jpg=mnist_2_jpg,\n",
        "        mnist_7_jpg=mnist_7_jpg,\n",
        "        mnist_8_jpg=mnist_8_jpg,\n",
        "        train_test_split_factor=train_test_split,\n",
        "    )\n",
        "\n",
        "    split_job.outputs.training_data = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"training_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "    split_job.outputs.testing_data = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"testing_data\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"training_data\": split_job.outputs.training_data,\n",
        "        \"testing_data\": split_job.outputs.testing_data\n",
        "    }\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749409441205
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "version = \"1\"\n",
        "digits = [\"mnist_2_jpg\", \"mnist_7_jpg\", \"mnist_8_jpg\"]\n",
        "\n",
        "# Map them directly with expected keys\n",
        "digits_datasets = {\n",
        "    digit: Input(type=\"uri_folder\", path=f\"azureml:{digit}:{version}\")\n",
        "    for digit in digits\n",
        "}\n",
        "\n",
        "print(digits_datasets)\n",
        "\n",
        "# Create pipeline job\n",
        "train_test_pipeline = mnist_images_traintest_split_pipeline(\n",
        "    **digits_datasets,\n",
        "    train_test_split=20\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749409557901
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit to Azure ML\n",
        "pipeline_job = ml_client.jobs.create_or_update(\n",
        "    train_test_pipeline,\n",
        "    experiment_name=\"mnist_split_pipeline\"\n",
        ")\n",
        "\n",
        "# Open in browser\n",
        "import webbrowser\n",
        "webbrowser.open(pipeline_job.studio_url)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749409571984
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the dataset "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating environment for training "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml.entities import Environment\n",
        "import os\n",
        "\n",
        "custom_env_name = \"aml-Tensorflow-Pillow\"\n",
        "\n",
        "pipeline_job_env = Environment(\n",
        "    name=custom_env_name,\n",
        "    description=\"Custom environment for AI Training (with Pillow)\",\n",
        "    tags={\"Pillow\": \"10.0.1\", \"Tensorflow\": \"2.4.1\"},\n",
        "    conda_file=os.path.join(\"components\", \"training\", \"conda.yaml\"),\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")\n",
        "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
        "\n",
        "print(\n",
        "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Environment with name aml-Tensorflow-Pillow is registered to workspace, the environment version is 1\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1749416890551
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import command, Input, Output\n",
        "import os\n",
        "\n",
        "mnist_training_component = command(\n",
        "    name=\"mnist_training\",\n",
        "    display_name=\"MNIST CNN Training\",\n",
        "    description=\"Trains a CNN on 28x28 grayscale MNIST digit JPGs using 3-digit classification.\",\n",
        "    inputs={\n",
        "        \"training_folder\": Input(type=\"uri_folder\"),\n",
        "        \"testing_folder\": Input(type=\"uri_folder\"),\n",
        "        \"epochs\": Input(type=\"number\")\n",
        "    },\n",
        "    outputs={\n",
        "        \"output_folder\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
        "    },\n",
        "    code=os.path.join(\"components\", \"training\", \"code\"),  # This must contain train.py & utils.py\n",
        "    command=\"\"\"\n",
        "        python train.py \\\n",
        "        --training_folder ${{inputs.training_folder}} \\\n",
        "        --testing_folder ${{inputs.testing_folder}} \\\n",
        "        --output_folder ${{outputs.output_folder}} \\\n",
        "        --epochs ${{inputs.epochs}}\n",
        "    \"\"\",\n",
        "    environment=\"aml-Tensorflow-Pillow@latest\"\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1749416892307
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "registered_training_component = ml_client.components.create_or_update(mnist_training_component)\n",
        "print(\n",
        "    f\"Component {registered_training_component.name} registered (version: {registered_training_component.version})\"\n",
        ")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1749416833755
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.ml import dsl\n",
        "\n",
        "@dsl.pipeline(\n",
        "    compute=\"cpu-sadiksha-auto\",  # Replace with your compute name\n",
        "    description=\"MNIST Digit Classification Training Pipeline\",\n",
        ")\n",
        "def mnist_training_pipeline(training_folder: Input, testing_folder: Input, epochs: int):\n",
        "    training_job = mnist_training_component(\n",
        "        training_folder=training_folder,\n",
        "        testing_folder=testing_folder,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "    training_job.outputs.output_folder = Output(\n",
        "        type=\"uri_folder\",\n",
        "        name=\"mnist_trained_model_output\",\n",
        "        mode=\"rw_mount\"\n",
        "    )\n",
        "\n",
        "    return {\"output_data\": training_job.outputs.output_folder}\n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1749416894088
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import webbrowser\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "mnist_pipeline_instance = mnist_training_pipeline(\n",
        "    training_folder=Input(type=\"uri_folder\", path=\"azureml:training_data:1\"),\n",
        "    testing_folder=Input(type=\"uri_folder\", path=\"azureml:testing_data:1\"),\n",
        "    epochs=20,\n",
        ")\n",
        "\n",
        "mnist_pipeline_job = ml_client.jobs.create_or_update(\n",
        "    mnist_pipeline_instance,\n",
        "    experiment_name=\"mnist_training_pipeline\",\n",
        ")\n",
        "\n",
        "print(f\"✅ Pipeline submitted: {mnist_pipeline_job.name}\")\n",
        "webbrowser.open(mnist_pipeline_job.studio_url)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nClass BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n\u001b[32mUploading code (0.01 MBs): 100%|██████████| 7062/7062 [00:00<00:00, 257586.90it/s]\n\u001b[39m\n\npathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Pipeline submitted: silver_ant_y8b8l74jz0\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "False"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1749416902305
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}